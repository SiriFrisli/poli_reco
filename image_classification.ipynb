{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"text\"\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"Convert an image file to a base64 encoded string\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "def perform_ocr(image_path):\n",
    "    \"\"\"Perform OCR on the given image\"\"\"\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "    response = requests.post(\n",
    "        \n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_client = ollama.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'D:\\\\Images\\\\Training_images\\\\data\\\\Erna Solberg\\\\Erna Solberg_20.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = {\n",
    "    'role': 'user',\n",
    "    'content': 'Describe this image',\n",
    "    'images': [image_path]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama_client.chat(\n",
    "    model='llava:34b',\n",
    "    messages=[message]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a person who appears to be middle-aged, wearing a dark top with what seems to be the bottom of an orange blouse or dress underneath. The individual has short hair and is looking slightly off to the side with a neutral expression. In the background, there's a blurred blue sign with text on it, but due to the focus on the person in the foreground, the text is not legible. It seems like this photo was taken at an event or conference where media coverage may have been present. The setting suggests a formal or semi-formal atmosphere.\n"
     ]
    }
   ],
   "source": [
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "input_dir = 'output_images_detected'  # Directory with the true data\n",
    "data_dir = 'data'                      # Directory with subfolders for each class\n",
    "\n",
    "# Define class names\n",
    "class_names = [\n",
    "    'Jonas Gahr Støre',\n",
    "    'Erna Solberg', \n",
    "    'Bent Høie',\n",
    "    'Lan Marie Berg',\n",
    "    'Sylvi Lysthaug',\n",
    "    'Espen Rostrup Nakstad',\n",
    "    'Trygve Slagsvold Vedum',\n",
    "    'Camilla Stoltenberg',\n",
    "    'Fredrik Solvang',\n",
    "    'Donald Trump',\n",
    "    'Joe Biden',\n",
    "    'Anthony Fauci',\n",
    "    'Bill Gates',\n",
    "    'Random People Walking',\n",
    "    'random people',\n",
    "    'random facebook post',\n",
    "    'random twitter post',\n",
    "    'casual snapshots',\n",
    "    'lifestyle photos',\n",
    "    'everyday moments',\n",
    "    'food photo',\n",
    "    'nature photo'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize LLaVA model\n",
    "llava_model = LLava(model_size=\"34b\", use_gpu=True)\n",
    "\n",
    "# Process images\n",
    "for img_path in os.listdir(input_dir):\n",
    "    img_full_path = os.path.join(input_dir, img_path)\n",
    "    \n",
    "    # Perform inference\n",
    "    result = llava_model.predict(img_full_path)\n",
    "    \n",
    "    # Get predicted class\n",
    "    predicted_class = result['class']\n",
    "    \n",
    "    if predicted_class in class_names:\n",
    "        print(f\"Image: {img_path}, Predicted Class: {predicted_class}\")\n",
    "    else:\n",
    "        print(f\"Image: {img_path} - Unknown or generic image\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poli_reco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
