{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script document the framework used in the paper \"Multimodal Critique of Authority – Humor as a Function of Dissent during the COVID-19 Pandemic\" (paper in progress). \n",
    "\n",
    "The framework in question can be summarized as following:\n",
    "\n",
    "### Step 1: Contrastive image-text loss for representation learning\n",
    "### Step 2: Hybrid-modal attention for cross-modal fusion\n",
    "### Step 3: Humor classification\n",
    "### Step 4: Mutual learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from info_nce import InfoNCE, info_nce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sirifris\\.conda\\envs\\poli_reco\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load M-CLIP model, this will be used for the texts embeddings\n",
    "model_name = \"M-CLIP/XLM-Roberta-Large-Vit-B-32\"\n",
    "clip_text_model = pt_multilingual_clip.MultilingualCLIP.from_pretrained(model_name)\n",
    "clip_tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available, otherwise fallback to CPU\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sirifris\\.conda\\envs\\poli_reco\\lib\\site-packages\\easyocr\\detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "c:\\Users\\sirifris\\.conda\\envs\\poli_reco\\lib\\site-packages\\easyocr\\recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# initalize the ocr\n",
    "reader = easyocr.Reader([\"no\", \"en\"])\n",
    "PIL.Image.ANTIALIAS = PIL.Image.LANCZOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_features(text):\n",
    "    \"\"\"Extracts text features using M-CLIP/XLM-Roberta-Large-Vit-B-32, handling long texts.\"\"\"\n",
    "    try:\n",
    "        max_tokens = 512  # \n",
    "        # Tokenize the input text\n",
    "        tokens = clip_tokenizer(text, return_tensors=\"pt\", padding=False, truncation=False).input_ids[0]\n",
    "        # Ensures no empty chunk is created\n",
    "        token_chunks = [tokens[i:i + max_tokens] for i in range(0, len(tokens), max_tokens)]\n",
    "    \n",
    "        # Check if any chunk is empty (which could happen with very short texts or edge cases)\n",
    "        if any(len(chunk) == 0 for chunk in token_chunks):\n",
    "            print(\"⚠️ Warning: Found empty token chunks!\")\n",
    "            return None  # Early exit if there are empty chunks\n",
    "        # Decode chunks back into text\n",
    "        text_chunks = [clip_tokenizer.decode(chunk, skip_special_tokens=True) for chunk in token_chunks]\n",
    "        \n",
    "        # Process each chunk and extract its features\n",
    "        chunk_features = []\n",
    "        for chunk in text_chunks:\n",
    "            # Tokenize each chunk and get the model features\n",
    "            inputs = clip_tokenizer(chunk, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "            with torch.no_grad():\n",
    "                features = clip_text_model.forward([chunk], clip_tokenizer).squeeze().cpu().numpy()\n",
    "            chunk_features.append(features)\n",
    "        \n",
    "        # Average the features from all chunks to get the final representation\n",
    "        final_text_features = np.mean(chunk_features, axis=0) if chunk_features else np.zeros((512,))\n",
    "        \n",
    "        return final_text_features\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error extracting text features: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_easyocr(image_path):\n",
    "    \"\"\"Extracts text from an image using EasyOCR.\"\"\"\n",
    "    try:\n",
    "        results = reader.readtext(image_path, detail=0)  # Extract text without coordinates\n",
    "        return \" \".join(results)  # Join extracted words into a single string\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ OCR failed for {image_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").eval()\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Function to extract image features\n",
    "def get_image_features(image_path):\n",
    "    \"\"\"Extracts image embeddings from CLIP.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.get_image_features(**inputs)\n",
    "    return image_features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultimodalDataset(Dataset):\n",
    "#     def __init__(self, dataframe, tokenizer, image_transform):\n",
    "#         self.dataframe = dataframe\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.image_transform = image_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = self.dataframe.iloc[idx][\"combined_text\"]\n",
    "#         image_path = self.dataframe.iloc[idx][\"image_path_image_filename_image_1\"]\n",
    "#         label = self.dataframe.iloc[idx][\"label\"]\n",
    "\n",
    "#         # Extract text features using get_text_features\n",
    "#         text_features = get_text_features(text)\n",
    "        \n",
    "#         # Extract image features using get_image_features\n",
    "#         image_features = get_image_features(image_path)\n",
    "\n",
    "#         return torch.tensor(text_features), torch.tensor(image_features), torch.tensor(label).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "df = pd.read_excel(\"D:/sample_images_full.xlsx\")\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "df[\"image_path_image_filename_image_1\"] = df[\"image_path_image_filename_image_1\"].str.replace(r\"^D:/\", \"E:/\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sirifris\\.conda\\envs\\poli_reco\\lib\\site-packages\\PIL\\Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "c:\\Users\\sirifris\\.conda\\envs\\poli_reco\\lib\\site-packages\\PIL\\Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df[\"image_text\"] = df[\"image_path_image_filename_image_1\"].apply(extract_text_easyocr)\n",
    "df[\"combined_text\"] = df[\"tweet\"] + \" \" + df[\"image_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: index out of range in self\n",
      "⚠️ Error extracting text features: The expanded size of the tensor (515) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 515].  Tensor sizes: [1, 514]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sirifris\\.conda\\envs\\poli_reco\\lib\\site-packages\\PIL\\Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df[\"text_features\"] = df[\"combined_text\"].apply(get_text_features)\n",
    "df[\"image_features\"] = df[\"image_path_image_filename_image_1\"].apply(get_image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"text_features\", \"image_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df[\"text_features\"] and df[\"image_features\"] are numpy arrays\n",
    "text_embeddings = torch.tensor(df[\"text_features\"].tolist())\n",
    "image_embeddings = torch.tensor(df[\"image_features\"].tolist())\n",
    "\n",
    "# text_embeddings = text_embeddings.unsqueeze(0)  # Shape becomes (1, batch_size, embedding_dim)\n",
    "# image_embeddings = image_embeddings.unsqueeze(0)\n",
    "image_embeddings = image_embeddings.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2158, 512])\n"
     ]
    }
   ],
   "source": [
    "print(text_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2158, 512])\n"
     ]
    }
   ],
   "source": [
    "print(image_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    1773\n",
      "1     385\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the temperature parameter for scaling the dot-product similarity\n",
    "temperature = 0.07\n",
    "\n",
    "def contrastive_loss(text_embeddings, image_embeddings, temperature=0.07):\n",
    "    # Normalize the embeddings\n",
    "    text_embeddings = F.normalize(text_embeddings, p=2, dim=1)\n",
    "    image_embeddings = F.normalize(image_embeddings, p=2, dim=1)\n",
    "    \n",
    "    # Compute similarity matrix (dot product)\n",
    "    similarity_matrix = torch.matmul(text_embeddings, image_embeddings.T) / temperature\n",
    "\n",
    "    # Create labels for positive pairs (diagonal of the similarity matrix)\n",
    "    labels = torch.arange(text_embeddings.size(0)).to(text_embeddings.device)\n",
    "    \n",
    "    # Cross-entropy loss based on similarity matrix\n",
    "    loss = F.cross_entropy(similarity_matrix, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FusionModel(nn.Module):\n",
    "#     def __init__(self, embedding_dim, num_heads=8):\n",
    "#         super(FusionModel, self).__init__()\n",
    "#         self.attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads)\n",
    "#         self.linear = nn.Linear(embedding_dim, embedding_dim)  # Optional for dimension adjustment\n",
    "\n",
    "#     def forward(self, text_embeddings, image_embeddings):\n",
    "#         # Concatenate text and image embeddings along the batch dimension\n",
    "#         embeddings = torch.cat([text_embeddings, image_embeddings], dim=0)  # (batch_size*2, embedding_dim)\n",
    "        \n",
    "#         # Reshape to match the format required by MultiheadAttention (sequence_length, batch_size, embedding_dim)\n",
    "#         embeddings = embeddings.unsqueeze(0)  # (1, batch_size*2, embedding_dim)\n",
    "        \n",
    "#         # Apply multi-head attention\n",
    "#         attn_output, attn_output_weights = self.attention(embeddings, embeddings, embeddings)\n",
    "        \n",
    "#         # Reshape the output to match the original embedding shape\n",
    "#         fused_embeddings = attn_output.squeeze(0)  # (batch_size*2, embedding_dim)\n",
    "        \n",
    "#         # Optionally apply a final linear transformation\n",
    "#         fused_embeddings = self.linear(fused_embeddings)\n",
    "#         return fused_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, embed_dim=512, num_heads=8):\n",
    "        super(FusionModel, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)  # Ensures final output is [batch, 512]\n",
    "        self.norm = nn.LayerNorm(embed_dim)  # Normalization for stability\n",
    "\n",
    "    def forward(self, text_embeddings, image_embeddings):\n",
    "        # Ensure image_embeddings has the correct shape\n",
    "        image_embeddings = image_embeddings.squeeze(1)  # Removes extra dimension if present\n",
    "        \n",
    "        # Concatenate along sequence dimension: [batch, 2, 512]\n",
    "        combined = torch.stack([text_embeddings, image_embeddings], dim=1)\n",
    "\n",
    "        # Apply multi-head attention\n",
    "        attn_output, _ = self.multihead_attn(combined, combined, combined)  # Self-attention\n",
    "\n",
    "        # Aggregate: Use mean pooling across the 2 modalities\n",
    "        fused = attn_output.mean(dim=1)  # Shape: [batch, 512]\n",
    "\n",
    "        # Pass through a final FC layer + normalization\n",
    "        fused = self.fc(fused)\n",
    "        fused = self.norm(fused)\n",
    "\n",
    "        return fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = text_embeddings.size(1)  # Assume text and image embeddings have the same dimension\n",
    "fusion_model = FusionModel(embedding_dim)\n",
    "fused_embeddings = fusion_model(text_embeddings, image_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2158, 512])\n"
     ]
    }
   ],
   "source": [
    "print(fused_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0204,  0.3916,  0.5710,  ..., -1.5662,  0.4650, -1.0300],\n",
      "        [ 0.7083,  0.8559,  0.2113,  ..., -0.9875,  1.2207, -1.4478],\n",
      "        [ 1.3664,  1.8215,  1.4045,  ..., -0.3203,  2.1708, -1.2498],\n",
      "        [ 1.1744,  0.5577,  0.7000,  ..., -0.4145,  1.4421, -1.7461],\n",
      "        [-0.2091,  1.0547,  0.4468,  ..., -1.8466,  0.3201, -1.0512]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(fused_embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value: -4.789506435394287\n",
      "Max value: 4.397152423858643\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min value: {fused_embeddings.min()}\")\n",
    "print(f\"Max value: {fused_embeddings.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(fused_embeddings[:, 0].detach().numpy(), bins=50)\n",
    "plt.title(\"Histogram of First Dimension of Fused Embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sirifris\\AppData\\Local\\Temp\\ipykernel_23464\\1974732226.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\sirifris\\AppData\\Local\\Temp\\ipykernel_23464\\1974732226.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "X = fused_embeddings  # The fused embeddings\n",
    "y = df['label'].values  # The labels for humor classification (0 or 1)\n",
    "\n",
    "# Split the data into training and test sets (e.g., 80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Convert to PyTorch tensors for model training\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Convert to NumPy arrays for SMOTE\n",
    "X_train = np.array(X_train.tolist())  # Convert list of arrays to 2D NumPy array\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_train_resampled = torch.tensor(X_train_resampled, dtype=torch.float32)\n",
    "y_train_resampled = torch.tensor(y_train_resampled, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Print new class distribution\n",
    "from collections import Counter\n",
    "print(\"Resampled class distribution:\", Counter(y_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple feed-forward neural network for binary classification\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)  # Second fully connected layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation for binary output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation after the first layer\n",
    "        x = self.fc2(x)  # Apply the second layer\n",
    "        x = self.sigmoid(x)  # Apply sigmoid to get a probability (0-1)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = Classifier(input_dim=512)  # The input dimension matches the fused embedding size (512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6974\n",
      "Epoch [2/10], Loss: 0.6406\n",
      "Epoch [3/10], Loss: 0.6061\n",
      "Epoch [4/10], Loss: 0.5728\n",
      "Epoch [5/10], Loss: 0.5567\n",
      "Epoch [6/10], Loss: 0.5371\n",
      "Epoch [7/10], Loss: 0.5230\n",
      "Epoch [8/10], Loss: 0.5113\n",
      "Epoch [9/10], Loss: 0.4985\n",
      "Epoch [10/10], Loss: 0.4920\n"
     ]
    }
   ],
   "source": [
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing X to the model\n",
    "    outputs = model(X_train_resampled)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs.squeeze(), y_train_resampled.float())\n",
    "\n",
    "    # Backward pass: Compute gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       355\n",
      "           1       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.82       432\n",
      "   macro avg       0.41      0.50      0.45       432\n",
      "weighted avg       0.68      0.82      0.74       432\n",
      "\n",
      "Confusion Matrix:\n",
      " [[355   0]\n",
      " [ 77   0]]\n",
      "Accuracy: 0.8218\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sirifris\\.conda\\envs\\poli_reco\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sirifris\\.conda\\envs\\poli_reco\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sirifris\\.conda\\envs\\poli_reco\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sirifris\\.conda\\envs\\poli_reco\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)  # Get model outputs\n",
    "    predicted_labels = torch.argmax(predictions, dim=1)  # Convert logits to class labels\n",
    "\n",
    "    # Compute accuracy\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "    # Compute precision, recall, f1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, predicted_labels, average=\"binary\")\n",
    "\n",
    "    # Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predicted_labels))\n",
    "\n",
    "    # Print confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted_labels)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
